{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "from viewer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import tqdm\n",
    "def find_representative_cells(df, group_column, feature_columns, method='random', n=1):\n",
    "    # Ensure feature_columns is a list\n",
    "    if isinstance(feature_columns, str):\n",
    "        feature_columns = [feature_columns]\n",
    "\n",
    "    # Group by the specified column\n",
    "    groups = df.group_by(group_column)\n",
    "    # Initialize a list to hold the selected rows\n",
    "    selected_rows = []\n",
    "\n",
    "    for name, group in tqdm.tqdm(groups, total = len(df[group_column].unique())):\n",
    "        # Apply the selection method\n",
    "        if method == 'random':\n",
    "            # Randomly select n rows from the group\n",
    "            selected_rows.extend(group.sample(n=n, with_replacement=False))\n",
    "\n",
    "        elif method == 'geomean':\n",
    "            # Calculate the geometric mean of the feature columns for each group\n",
    "            geomean = group.select([pl.col(col).prod()**(1/len(group)) for col in feature_columns])\n",
    "            # Find the row closest to the geometric mean\n",
    "            closest = group[feature_columns].apply(lambda row: np.linalg.norm(row - geomean)).arg_min()\n",
    "            selected_rows.append(group.row(closest))\n",
    "\n",
    "        elif method == 'kmeans':\n",
    "            if group.shape[0]>60:\n",
    "                n_cells_in_each_cluster_unif=30\n",
    "            else:\n",
    "                n_cells_in_each_cluster_unif=int(group.shape[0]/5) \n",
    "        \n",
    "            n_clusts=int(group.shape[0]/n_cells_in_each_cluster_unif) \n",
    "            # Apply k-means clustering on the feature columns to find the most representative row\n",
    "            kmeans = KMeans(n_clusters=1, random_state=0, n_init = 10).fit(group[feature_columns].to_numpy())\n",
    "            centroid = kmeans.cluster_centers_[0]\n",
    "            closest = group[feature_columns].apply(lambda row: np.linalg.norm(row - centroid)).arg_min()\n",
    "            selected_rows.append(group.row(closest))\n",
    "        \n",
    "        elif method == 'kmedoid':\n",
    "            # Check if group is smaller than n\n",
    "            if len(group) < n:\n",
    "                raise ValueError(f\"Group {name} has fewer rows than the number of requested representatives.\")\n",
    "\n",
    "            # Initialize and fit the KMedoids\n",
    "            kmedoids = KMedoids(n_clusters=n, random_state=0).fit(group[feature_columns])\n",
    "\n",
    "            # Get the indices of the medoids\n",
    "            medoids_indices = kmedoids.medoid_indices_\n",
    "\n",
    "            # Select rows corresponding to medoids\n",
    "            for index in medoids_indices:\n",
    "                selected_rows.append(group.row(index))\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown method: choose 'random', 'geomean', or 'kmeans'\")\n",
    "\n",
    "    # Concatenate all selected rows into a new DataFrame\n",
    "    result_df = pl.concat(selected_rows)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def anndata_to_pandas(ad):\n",
    "    # Convert the main data matrix .X to a DataFrame\n",
    "    if isinstance(ad.X, (np.ndarray, np.generic)):  # If .X is already a dense matrix\n",
    "        df = pd.DataFrame(ad.X, columns=ad.var_names)\n",
    "    else:  # If .X is a sparse matrix\n",
    "        df = pd.DataFrame(ad.X.toarray(), columns=ad.var_names)\n",
    "\n",
    "    # Add observation metadata from .obs\n",
    "    df = pd.concat([ad.obs.reset_index(), df], axis=1)  # Reset index to align the data\n",
    "    \n",
    "    # Handling .obsm data\n",
    "    for key, matrix in ad.obsm.items():\n",
    "        if matrix.ndim == 2:  # Ensure the matrix is two-dimensional\n",
    "            obsm_df = pd.DataFrame(matrix, columns=[f\"{key}_{i}\" for i in range(matrix.shape[1])])\n",
    "            df = pd.concat([df, obsm_df.reset_index(drop=True)], axis=1)  # Concatenate to the main DataFrame\n",
    "        else:\n",
    "            print(f\"Skipping {key} as it is not 2-dimensional\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def pd_to_polars(df):\n",
    "    \"\"\"\n",
    "    Convert a Pandas DataFrame to Polars DataFrame and handle columns\n",
    "    with int and float categorical dtypes.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if isinstance(df[col].dtype, pd.CategoricalDtype):\n",
    "            if pd.api.types.is_integer_dtype(df[col].cat.categories.dtype):\n",
    "                df[col] = df[col].astype(int)\n",
    "                print(f\"Column [{col}] cast to int\")\n",
    "            elif pd.api.types.is_float_dtype(df[col].cat.categories.dtype):\n",
    "                df[col] = df[col].astype(float)\n",
    "                print(f\"Column [{col}] cast to float\")\n",
    "\n",
    "    return pl.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import tqdm\n",
    "\n",
    "def find_representative_cells(df, group_column, feature_columns, method='random', n=1):\n",
    "    # Ensure feature_columns is a list\n",
    "    if isinstance(feature_columns, str):\n",
    "        feature_columns = [feature_columns]\n",
    "\n",
    "    # Initialize a list to hold the selected rows\n",
    "    selected_rows = []\n",
    "\n",
    "    # Group by the specified column\n",
    "    groups = df.groupby(group_column)\n",
    "\n",
    "    for name, group in tqdm.tqdm(groups):\n",
    "        if name == \"unassigned\":\n",
    "            print(name, \"not a valid cluster\")\n",
    "            continue\n",
    "        # Apply the selection method\n",
    "        if method == 'random':\n",
    "            # Randomly select n rows from the group\n",
    "            selected_rows.append(group.sample(n=n))\n",
    "\n",
    "        elif method == 'geomean':\n",
    "            # Calculate the geometric mean of the feature columns for each group\n",
    "            geomean = group[feature_columns].apply(lambda x: np.prod(x)**(1/len(x)), axis=0)\n",
    "            # Find the row closest to the geometric mean\n",
    "            closest = (group[feature_columns] - geomean).apply(np.linalg.norm, axis=1).idxmin()\n",
    "            selected_rows.append(group.loc[[closest]])\n",
    "\n",
    "        elif method == 'kmeans':\n",
    "            if group.shape[0] > 60:\n",
    "                n_cells_in_each_cluster_unif = 30\n",
    "            else:\n",
    "                n_cells_in_each_cluster_unif = int(group.shape[0] / 5)\n",
    "\n",
    "            n_clusts = int(group.shape[0] / n_cells_in_each_cluster_unif)\n",
    "            # Apply k-means clustering on the feature columns to find the most representative row\n",
    "            kmeans = KMeans(n_clusters=n_clusts, random_state=0, n_init=10).fit(group[feature_columns])\n",
    "            centroid = kmeans.cluster_centers_[0]\n",
    "            closest = (group[feature_columns] - centroid).apply(np.linalg.norm, axis=1).idxmin()\n",
    "            selected_rows.append(group.loc[[closest]])\n",
    "\n",
    "        elif method == 'kmedoid':\n",
    "            # Check if group is smaller than n\n",
    "            if len(group) < n:\n",
    "                raise ValueError(f\"Group {name} has fewer rows than the number of requested representatives.\")\n",
    "\n",
    "            # Initialize and fit the KMedoids\n",
    "            kmedoids = KMedoids(n_clusters=n, random_state=0).fit(group[feature_columns].values)\n",
    "            \n",
    "            # Get the indices of the medoids\n",
    "            medoids_indices = kmedoids.medoid_indices_\n",
    "\n",
    "            # Select rows corresponding to medoids\n",
    "            for index in medoids_indices:\n",
    "                selected_rows.append(group.iloc[[index]])\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown method: choose 'random', 'geomean', or 'kmeans'\")\n",
    "\n",
    "    # Concatenate all selected rows into a new DataFrame\n",
    "    result_df = pd.concat(selected_rows, axis=0).reset_index(drop=True)\n",
    "    sorted_df = result_df.sort_values(by=['Metadata_cmpdName'], ascending=[True])\n",
    "    return sorted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_representatives_v2(df, box_size, grouping, n_cells):\n",
    "    df['Metadata_Site'] = df['Metadata_Site'].astype(str)\n",
    "    df['Metadata_Site'] = df['Metadata_Site'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "    views = []\n",
    "    # Define top row as labels\n",
    "    # Assuming you want to group by 'Metadata_Plate' and 'Metadata_Well'\n",
    "    site_row = []\n",
    "    for i in range(0, n_cells + 2):\n",
    "        if i == 0:\n",
    "            site_row.append(View(hover='(padding at top left)'))\n",
    "        elif i == (n_cells + 1):\n",
    "            site_row.append(View(hover='(padding at top right)'))\n",
    "        else:\n",
    "            site_row.append(View(overlay=f'Cell {i}', overlay_style=style7 + \":white-space: pre\", overlay_dir='S'))\n",
    "    views.append(site_row)\n",
    "    groups = df[grouping].unique()\n",
    "    y = 1\n",
    "    for g in groups:\n",
    "        row_views = []\n",
    "        print(g)\n",
    "        group = df[df[grouping] == g]\n",
    "        x = 1\n",
    "        for index, row in group.iterrows():\n",
    "                plate = row[\"Metadata_Plate\"]\n",
    "                well = row[\"Metadata_Well\"]\n",
    "                site = row[\"Metadata_Site\"]\n",
    "                center_x = row[\"Nuclei_Location_Center_X\"]\n",
    "                center_y = row[\"Nuclei_Location_Center_Y\"]\n",
    "                row_views.append(View(\n",
    "                    barcode=plate, well=well, site=site,\n",
    "                    #clip=ClipBox(center_x - box_size // 2, center_y - box_size // 2, box_size, box_size),\n",
    "                    clip = ClipSquare(center_x, center_y, box_size),\n",
    "                    #x = x,\n",
    "                    #y = y\n",
    "                ))\n",
    "                x += 1\n",
    "        y += 1\n",
    "        row_views.insert(0, View(overlay=g, overlay_style=style7 + \";text-align:right\", overlay_dir='E'))\n",
    "        views.append(row_views)\n",
    "    views.append([View(hover='(padding at bottom left)')])\n",
    "    return views\n",
    "\n",
    "def table(grid):\n",
    "    res = []\n",
    "    for y, row in enumerate(grid):\n",
    "        for x, cell in enumerate(row):\n",
    "            assert isinstance(cell, View), f'Execpted View, got: {cell} ({y=}, {x=})'\n",
    "            res += [replace(cell, x=x, y=y)]\n",
    "    #return res\n",
    "    return Viewer(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_representative_views(file_path, grouping_col, n_rep, method = \"kmedoid\", image_size = 250, compounds_filter = None):\n",
    "    print(\"Importing data\")\n",
    "    location_df = ad.read_h5ad(file_path)\n",
    "    if compounds_filter is not None:\n",
    "        location_df = location_df[location_df.obs['Metadata_cmpdName'].isin(compounds_filter)]\n",
    "    \n",
    "    location_pd = anndata_to_pandas(location_df)\n",
    "\n",
    "    #if compounds_filter is not None:\n",
    "    #    location_pd = location_pd[location_pd['Metadata_cmpdName'].isin(compounds_filter)]\n",
    "\n",
    "    # Reset the index to avoid issues with previous groupings\n",
    "    location_pd = location_pd.reset_index(drop=True)\n",
    "    feature_cols = [feat for feat in location_pd.columns if \"Feature\" in feat]\n",
    "    print(\"Finding representatives\", location_pd.shape)\n",
    "    representatives = find_representative_cells(location_pd, grouping_col, feature_cols, method=method, n=n_rep)\n",
    "    representative_sort = representatives.sort_values(by=[grouping_col])\n",
    "    print(\"Generating views\")\n",
    "    views = show_representatives_v2(representative_sort, image_size, grouping = grouping_col, n_cells = n_rep)\n",
    "    return views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find representative cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = find_representative_views(\"/home/jovyan/share/data/analyses/benjamin/cellxgene/sc_embedding_scanpy_Beactica_deep+cell_cellcycle2.h5ad\", \"Metadata_cmpdNameConc\", 10, image_size= 150, compounds_filter= [\"BORTEZOMIB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_single_cell(plate, well ,site, loc_x, loc_y, box_size):\n",
    "    view = View(\n",
    "                    barcode=plate, well=well, site=site,\n",
    "                    #clip=ClipBox(center_x - box_size // 2, center_y - box_size // 2, box_size, box_size),\n",
    "                    clip = ClipSquare(loc_x, loc_y, box_size),\n",
    "                    #x = x,\n",
    "                    #y = y\n",
    "                )\n",
    "    \n",
    "    return view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viewer(show_single_cell(\"PB000046\", \"M17\", 6, 2633, 253, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show cells in wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_treatment_scatter(df, x_coord_column, y_coord_column, treatment_column, x1, x2, y1, y2):\n",
    "    \"\"\"\n",
    "    Create a grid of scatter plots of points based on their spatial coordinates, \n",
    "    with each subplot corresponding to a different treatment group.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame containing the coordinate and treatment data.\n",
    "    x_coord_column (str): The name of the column containing x coordinates.\n",
    "    y_coord_column (str): The name of the column containing y coordinates.\n",
    "    treatment_column (str): The name of the column containing treatment labels.\n",
    "    \"\"\"\n",
    "    # Determine the number of treatment groups and setup the subplot grid\n",
    "    treatments = df[treatment_column].unique()\n",
    "    n_treatments = len(treatments)\n",
    "    n_cols = 3  # number of columns\n",
    "    n_rows = int(np.ceil(n_treatments / n_cols))  # calculate required number of rows\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows), squeeze=False, dpi = 300)\n",
    "    axes = axes.flatten()  # Flatten to 1D array for easy iteration\n",
    "\n",
    "    # Loop through each treatment and create a subplot\n",
    "    for i, treatment in enumerate(treatments):\n",
    "        ax = axes[i]\n",
    "        subset = df[df[treatment_column] == treatment]\n",
    "        \n",
    "        sns.scatterplot(data=subset, x=x_coord_column, y=y_coord_column, ax=ax,\n",
    "                        hue=\"Metadata_cmpdName\", palette=\"Set2\", legend=False, s = 5)  # Remove individual legends\n",
    "        \n",
    "\n",
    "        ax.axvline(x=x1, color='red', linestyle='--')  # Vertical line at x1\n",
    "        ax.axvline(x=x2, color='red', linestyle='--')  # Vertical line at x2\n",
    "        ax.axhline(y=y1, color='red', linestyle='--')  # Horizontal line at y1\n",
    "        ax.axhline(y=y2, color='red', linestyle='--')  # Horizontal line at y2\n",
    "        ax.set_title(f'Treatment: {treatment}')\n",
    "\n",
    "        ax.set_xlim(0, 2500)  # Adjust according to your data\n",
    "        ax.set_ylim(0, 2500)  # Adjust according to your data\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(n_treatments, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    # Create a single legend outside the rightmost subplot\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(1.1, 1), ncol=1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_treatment_scatter(your_dataframe, 'X_Coord', 'Y_Coord', 'Treatment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_pd['grit'] = location_pd['grit'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_treatment_scatter(location_pd, \"Nuclei_Location_Center_X\", \"Nuclei_Location_Center_Y\", \"Metadata_cmpdName\", 250, 2250, 250, 2250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_treatment_scatter(representative__old, \"Nuclei_Location_Center_X\", \"Nuclei_Location_Center_Y\", \"dmso_populations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
