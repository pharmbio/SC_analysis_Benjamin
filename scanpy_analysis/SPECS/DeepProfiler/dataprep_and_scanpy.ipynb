{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc \n",
    "import anndata as ad\n",
    "import polars as pl\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.read_h5ad(\"/home/jovyan/share/data/analyses/benjamin/cellxgene/SPECS/cellprofiler/data/umap__dmso_only.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def sample_groups(df, grouping_cols, ratio):\n",
    "    subsampled_data = []\n",
    "    # Group by the specified columns only in the filtered DataFrame\n",
    "    grouped = df.groupby(grouping_cols)\n",
    "    # For each group, subsample and append to the subsampled_data list, with progress bar\n",
    "    for name, group in tqdm.tqdm(grouped, desc=\"Subsampling groups\", unit=\"group\"):\n",
    "        #if not (any(df[\"Metadata_cmpdName\"].unique()) == \"[DMSO]\") & int(len(group)*ratio) < 5:\n",
    "        #    subsampled_group = group\n",
    "        #else:\n",
    "        subsampled_group = group.sample(fraction=ratio, seed=42)\n",
    "        subsampled_data.append(subsampled_group)\n",
    "    # Concatenate the subsampled groups together\n",
    "    subsampled_df = pl.concat(subsampled_data)\n",
    "    return subsampled_df\n",
    "\n",
    "\n",
    "def sample_compounds(df1, df2, sampling_rate, mode =\"normal\"):\n",
    "    #Filter out sorbitol because neg control comp\n",
    "    df1 = df1.filter(~(pl.col(\"Metadata_cmpdName\") == \"[SORB]\"))\n",
    "    df2 = df2.filter(~(pl.col(\"Metadata_cmpdName\") == \"[SORB]\"))\n",
    "    # Step 1: Extract \"DMSO\" values from first DataFrame\n",
    "\n",
    "    # Sample DMSO group based on this ratio\n",
    "    # Initialize dictionary to hold dataframes for each compound including DMSO\n",
    "    if mode == \"dmso_only\":\n",
    "        # Sample only DMSO group, ensuring random distribution from each well\n",
    "        dmso_sampled  = sample_groups(df1.filter(pl.col(\"Metadata_cmpdName\") == \"[DMSO]\"), [\"Metadata_Plate\", \"Metadata_Well\"], sampling_rate)\n",
    "        dmso_sampled = dmso_sampled.with_columns(pl.lit(\"cell_na\").alias(\"Metadata_Cell_Identity\"))\n",
    "        dmso_sampled = dmso_sampled.with_columns(pl.lit(0).cast(pl.Float64).alias(\"grit\"))\n",
    "        dmso_sampled = dmso_sampled.with_columns(dmso_sampled['moa'].cast(pl.Utf8))\n",
    "        df2 = df2.with_columns(df2['moa'].cast(pl.Utf8))\n",
    "        sampled_df = pl.concat([dmso_sampled, df2.filter(~((pl.col(\"Metadata_cmpdName\") == \"[DMSO]\"))).drop(\"group\")])\n",
    "        return(sampled_df)\n",
    "    # Sample other compounds\n",
    "    elif mode == \"normal\":\n",
    "        dmso_values = list(df2.filter(pl.col(\"Metadata_cmpdName\") == \"[DMSO]\")[\"Metadata_Cell_Identity\"])\n",
    "        avg_compound_counts = df1.groupby([\"Metadata_cmpdName\", \"Metadata_Plate\", \"Metadata_Well\"]).agg(pl.count().alias('count')).groupby(\"Metadata_cmpdName\").agg(pl.mean(\"count\").alias(\"avg_count\"))\n",
    "        # Find the compound with the highest average count, excluding \"DMSO\"\n",
    "        average_comp = avg_compound_counts.filter(~(pl.col(\"Metadata_cmpdName\") == \"[DMSO]\")).select(pl.max(\"avg_count\"))[\"avg_count\"][0]\n",
    "        # Calculate the average count for DMSO\n",
    "        dmso_avg_count = avg_compound_counts.filter(pl.col(\"Metadata_cmpdName\") == \"[DMSO]\")[\"avg_count\"][0]\n",
    "        # Calculate ratio for DMSO based on the compound with the highest average count\n",
    "        #dmso_ratio = (dmso_avg_count / average_comp)\n",
    "        dmso_ratio = 1\n",
    "        max_rows = 0\n",
    "        print(dmso_ratio)\n",
    "        cmpd_sampled = pl.DataFrame()\n",
    "        for cmpd in df1[\"Metadata_cmpdName\"].unique():\n",
    "            if cmpd != \"[DMSO]\":\n",
    "                cmpd_sample = sample_groups(df2.filter(pl.col(\"Metadata_cmpdName\") == cmpd), [\"Metadata_Plate\", \"Metadata_Well\"], sampling_rate).drop(\"group\")\n",
    "                if \"moa\" in cmpd_sample.columns:\n",
    "                    cmpd_sample = cmpd_sample.with_columns(cmpd_sample['moa'].cast(pl.Utf8))\n",
    "                cmpd_sampled = pl.concat([cmpd_sampled, cmpd_sample])\n",
    "                num_rows = cmpd_sample.shape[0]\n",
    "                if num_rows > max_rows:\n",
    "                    max_rows = num_rows\n",
    "\n",
    "        if max_rows*dmso_ratio < len(dmso_values):\n",
    "            # if dmso samples would be smaller than number of grit reference dmso cells, only sample using those!\n",
    "            dmso_df = df2.filter(pl.col(\"Metadata_cmpdName\") == \"[DMSO]\").drop(\"group\")\n",
    "        else:\n",
    "            dmso_df = df1.filter(pl.col(\"Metadata_cmpdName\") == \"[DMSO]\")\n",
    "\n",
    "        dmso_sample = max_rows*dmso_ratio / dmso_df.shape[0]\n",
    "        dmso_sampled  = sample_groups(dmso_df, [\"Metadata_Plate\", \"Metadata_Well\"], dmso_sample)\n",
    "        dmso_sampled = dmso_sampled.with_columns(pl.lit(\"cell_na\").alias(\"Metadata_Cell_Identity\"))\n",
    "        dmso_sampled = dmso_sampled.with_columns(pl.lit(0).cast(pl.Float64).alias(\"grit\"))\n",
    "        if \"moa\" in dmso_sampled.columns:\n",
    "            dmso_sampled = dmso_sampled.with_columns(dmso_sampled['moa'].cast(pl.Utf8))\n",
    "        return pl.concat([dmso_sampled, cmpd_sampled])\n",
    "\n",
    "    elif mode == \"equal_sampling\":\n",
    "        cmpd_sampled = pl.DataFrame()\n",
    "        for cmpd in df1[\"Metadata_cmpdName\"].unique():\n",
    "            if cmpd == \"[DMSO]\":\n",
    "                cmpd_sample = sample_groups(df1.filter(pl.col(\"Metadata_cmpdName\") == cmpd), [\"Metadata_Plate\", \"Metadata_Well\"], sampling_rate).drop(\"group\")\n",
    "                cmpd_sample = cmpd_sample.with_columns(pl.lit(\"cell_na\").alias(\"Metadata_Cell_Identity\"))\n",
    "                cmpd_sample = cmpd_sample.with_columns(pl.lit(0).cast(pl.Float64).alias(\"grit\"))\n",
    "            else:\n",
    "                cmpd_sample = sample_groups(df2.filter(pl.col(\"Metadata_cmpdName\") == cmpd), [\"Metadata_Plate\", \"Metadata_Well\"], sampling_rate).drop(\"group\")\n",
    "            cmpd_sample = cmpd_sample.with_columns(cmpd_sample['moa'].cast(pl.Utf8))\n",
    "            cmpd_sampled = pl.concat([cmpd_sampled, cmpd_sample])\n",
    "        return cmpd_sampled    \n",
    "    else:\n",
    "        print(f\"{mode} not valid as a sampling mode!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = \"/home/jovyan/share/data/analyses/benjamin/Single_cell_project_rapids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs3k_plates = ['P101382',\n",
    " 'P101339',\n",
    " 'P101338',\n",
    " 'P101337',\n",
    " 'P101354',\n",
    " 'P101350',\n",
    " 'P101360',\n",
    " 'P101375',\n",
    " 'P101363',\n",
    " 'P101335',\n",
    " 'P101373',\n",
    " 'P101372',\n",
    " 'P101352',\n",
    " 'P101334',\n",
    " 'P101369',\n",
    " 'P101336',\n",
    " 'P101345',\n",
    " 'P101377',\n",
    " 'P101346',\n",
    " 'P101366',\n",
    " 'P101359',\n",
    " 'P101361',\n",
    " 'P101364',\n",
    " 'P101365',\n",
    " 'P101362',\n",
    " 'P101374',\n",
    " 'P101380',\n",
    " 'P101367',\n",
    " 'P101358',\n",
    " 'P101342',\n",
    " 'P101371',\n",
    " 'P101341',\n",
    " 'P101368',\n",
    " 'P101348',\n",
    " 'P101370',\n",
    " 'P101379',\n",
    " 'P101386',\n",
    " 'P101353',\n",
    " 'P101381',\n",
    " 'P101351',\n",
    " 'P101357',\n",
    " 'P101384',\n",
    " 'P101347',\n",
    " 'P101343',\n",
    " 'P101387',\n",
    " 'P101385',\n",
    " 'P101355',\n",
    " 'P101340',\n",
    " 'P101378',\n",
    " 'P101344',\n",
    " 'P101349',\n",
    " 'P101376',\n",
    " 'P101356']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "import pandas as pd\n",
    "mad_norm_df = pl.read_parquet(os.path.join(PROJECT_DIR, 'SPECS/deepprofiler/Results/sc_profiles_normalized_SPECS3K.parquet'))\n",
    "mad_norm_df = mad_norm_df.filter(pl.col('Metadata_Plate').is_in(specs3k_plates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_fixed = [f for f in mad_norm_df.columns if \"Feature\" in f]\n",
    "grit_filt_df = pl.read_parquet(os.path.join(PROJECT_DIR, \"SPECS/sc_profiles_all_grit_NODUPLICATES.parquet\")).filter(pl.col(\"Sampled\") == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grit_filter_df_sampled = sample_compounds(mad_norm_df, grit_filt_df, sampling_rate= 1, mode = \"normal\")\n",
    "grit_filter_df_sampled_pd = grit_filter_df_sampled.to_pandas()\n",
    "meta_features = [col for col in grit_filter_df_sampled_pd.columns if col not in features_fixed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grit_filter_df_sampled.write_parquet(\"sc_specs3k_ref_noduplicates_all_grit.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grit_filter_df_sampled_low = grit_filter_df_sampled.filter((pl.col(\"grit\") < 4) & (pl.col(\"grit\") > 0.8) | (pl.col(\"Metadata_cmpdName\") == \"[DMSO]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grit_filter_df_sampled_low.groupby(\"Metadata_cmpdName\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in grit_filter_df_sampled_low.columns if \"Feature\" in col]\n",
    "meta_features = [col for col in grit_filter_df_sampled_low.columns if col not in features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run scanpy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.AnnData(X = grit_filter_df_sampled_low.to_pandas()[features], obs = grit_filter_df_sampled_low.to_pandas()[meta_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scanpy(adata):\n",
    "    sc.tl.pca(adata, svd_solver='arpack')\n",
    "    sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50)\n",
    "    sc.tl.paga(adata, groups = \"Metadata_cmpdName\")\n",
    "    sc.pl.paga(adata, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "    sc.tl.umap(adata, init_pos='paga')\n",
    "    sc.tl.leiden(adata, key_added='clusters', resolution=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_an = run_scanpy(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"/home/jovyan/share/data/analyses/benjamin/cellxgene/sc_embedding_scanpy_SPECS3K_ref_NODUP_grit_filtered.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca(adata, color = \"Metadata_cmpdName\",  palette=\"Set2\")\n",
    "sc.pl.umap(adata, color = \"Metadata_cmpdName\",  palette=\"Set2\")\n",
    "sc.pl.umap(adata, color = \"grit\",  palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in adata.obs.columns:\n",
    "    if issubclass(adata.obs[col].dtype.type, pd.api.types.pandas_dtype('object').type):\n",
    "        adata.obs[col] = adata.obs[col].apply(lambda x: str(x) if pd.notnull(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata.obs[\"compound_name_right\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write('sc_embedding_specs5k_undersampled_sign.h5ad')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in cellxgene embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CXG_DIR = \"/home/jovyan/share/data/analyses/benjamin/cellxgene//SPECS/deepprofiler/embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_keys(adata):\n",
    "    def find_key_with_substring(obsm, substring):\n",
    "        for key in obsm.keys():\n",
    "            if substring in key:\n",
    "                return key\n",
    "        return None\n",
    "\n",
    "    # Find the keys\n",
    "    pca_key = find_key_with_substring(adata.obsm, 'pca')\n",
    "    umap_key = find_key_with_substring(adata.obsm, 'dmso')\n",
    "    if umap_key == None:\n",
    "        umap_key = find_key_with_substring(adata.obsm, 'emb')\n",
    "\n",
    "    # Rename the keys if they are found\n",
    "    if pca_key:\n",
    "        adata.obsm['X_pca'] = adata.obsm[pca_key]\n",
    "        #del adata.obsm[pca_key]\n",
    "\n",
    "    if umap_key:\n",
    "        adata.obsm['X_umap'] = adata.obsm[umap_key]\n",
    "        #del adata.obsm[umap_key]\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "import anndata as ad\n",
    "emb_dict = {}\n",
    "ref_comp = [\"berb\", \"cao\", \"etop\", \"fenb\", \"flup\", \"tetr\", \"dmso_only\"]\n",
    "h5ad_files = [file for file in os.listdir(CXG_DIR) if file.endswith(\".h5ad\")]\n",
    "\n",
    "for comp in tqdm.tqdm(ref_comp):\n",
    "   for filename in h5ad_files:\n",
    "        # Check if the current string is in the filename\n",
    "        if comp in filename and filename.endswith(\".h5ad\"):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(CXG_DIR, filename)\n",
    "            # Load the .h5ad file\n",
    "            temp = ad.read_h5ad(file_path)\n",
    "            temp_fix = fix_keys(temp)\n",
    "            emb_dict[comp] = temp_fix\n",
    "            # Optional: Print a message\n",
    "            print(f\"Loaded {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ad.read_h5ad(os.path.join(CXG_DIR, \"sc_embedding_scanpy_SPECS3K_ref_NODUP_grit_filtered.h5ad\"))\n",
    "temp_fix = fix_keys(temp)\n",
    "emb_dict[\"all\"] = temp_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "# Inital setting for plot\n",
    "from matplotlib import rcParams\n",
    "with plt.rc_context({\"figure.figsize\": (8, 8), \"figure.dpi\": (300)}):\n",
    "    for key, item in emb_dict.items():\n",
    "        print(key)\n",
    "        sc.pl.umap(item, color = \"Metadata_cmpdName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_umap_grid_colored(anndata_dict, color_by, n_cols=3):\n",
    "    \"\"\"\n",
    "    Create a grid of UMAP plots from a dictionary of AnnData objects, colored by a specified column.\n",
    "    \n",
    "    Parameters:\n",
    "    anndata_dict (dict): A dictionary of AnnData objects.\n",
    "    color_by (str): Column name to color by.\n",
    "    n_cols (int): Number of columns in the grid.\n",
    "    \"\"\"\n",
    "    # Determine all unique categories across all AnnData objects\n",
    "    anndata_dict = {k: v for k, v in anndata_dict.items() if k != 'all'}\n",
    "    all_categories = set()\n",
    "    for adata in anndata_dict.values():\n",
    "        all_categories.update(adata.obs[color_by].astype(str))\n",
    "\n",
    "    # Sort categories for consistent ordering and create color palette\n",
    "    sorted_categories = sorted(list(all_categories))\n",
    "    color_palette = sc.pl.palettes.default_20 # Use any large enough palette or define your own\n",
    "    color_map = {cat: color_palette[i % len(color_palette)] for i, cat in enumerate(sorted_categories)}\n",
    "    #color_map = {'big_dmso': '#1f77b4', 'small_dmso': '#ff7f0e', 'small_FLUP': '#279e68', 'big_FLUP': '#d62728', 'big_ETOP': '#aa40fc', 'small_ETOP': '#8c564b', 'big_TETR': '#e377c2', 'small_TETR': '#b5bd61', 'small_CA-O': '#17becf', 'big_CA-O': '#aec7e8', 'unassigned': '#ffbb78', 'BERB': '#98df8a', 'FEB': '#ff9896'}\n",
    "    print(color_map)\n",
    "    # Set up the figure for subplots\n",
    "    n_rows = int(np.ceil(len(anndata_dict) / n_cols))\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
    "    axs = axs.flatten()  # Flatten to make indexing axs easier\n",
    "\n",
    "    all_handles = []\n",
    "    all_labels = set()\n",
    "    \n",
    "    # Plot UMAP for each AnnData object\n",
    "    for ax, (key, adata) in zip(axs, anndata_dict.items()):\n",
    "        sc.pl.umap(adata, color=color_by, ax=ax, show=False, \n",
    "                   title=key, frameon=False,\n",
    "                   palette=color_map,\n",
    "                   legend_loc = \"none\")  # Apply the consistent color map\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        all_handles.extend(handles)\n",
    "        all_labels.update(labels)\n",
    "        # Remove axis titles (optional, for cleaner look)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "    # Hide any extra axes\n",
    "    for i in range(len(anndata_dict), len(axs)):\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    # Create an overall title\n",
    "    plt.suptitle('UMAP Grid', fontsize=16)\n",
    "\n",
    "    # Add a single legend outside the plots\n",
    "    # Get handles and labels for legend from the last plot\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=3, bbox_to_anchor=(0.5, 0.01))\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "with plt.rc_context({\"figure.figsize\": (8, 8), \"figure.dpi\": (300)}):\n",
    "    plot_umap_grid_colored(emb_dict, \"Metadata_cmpdName\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def plot_single_umap_colored(adata, color_by):\n",
    "    # Calculate the count of each category in the color_by column\n",
    "    category_counts = adata.obs[color_by].value_counts()\n",
    "\n",
    "    # Create a color palette\n",
    "    #color_map = {'berb': '#1f77b4', 'cao': '#ff7f0e', 'dmso_big': '#279e68', 'dmso_small': '#d62728', 'etop_big': '#aa40fc', 'etop_nocluster': '#8c564b', 'etop_small': '#e377c2', 'fenb': '#b5bd61', 'flup': '#17becf', 'tetr_big': '#aec7e8', 'tetr_nocluster': '#ffbb78'}\n",
    "    color_map = {'[BERB]': '#1f77b4', '[CA-0]': '#ff7f0e', '[DMSO]': '#279e68', '[ETOP]': '#d62728', '[FENB]': '#aa40fc', '[FLUP]': '#8c564b', '[TETR]': '#e377c2'}\n",
    "    # Create figure and axis for UMAP plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))  # Adjust figure size as needed\n",
    "\n",
    "    # Create UMAP plot\n",
    "    sc.pl.umap(adata, color=color_by, ax=ax, show=False,\n",
    "               title=f'UMAP colored by {color_by}', \n",
    "               frameon=False, legend_loc='none', \n",
    "               palette=color_map, s = 2)\n",
    "\n",
    "    # Create a custom legend for all categories with counts\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color='w',\n",
    "                              label=f\"{cat} (n={category_counts[cat]})\",\n",
    "                              markerfacecolor=color_map[cat], markersize=10)\n",
    "                       for cat in category_counts.index]\n",
    "\n",
    "    # Place legend outside the plot to the right\n",
    "    ax.legend(handles=legend_elements, title=color_by, loc='center left',\n",
    "              bbox_to_anchor=(1, 0.5), ncol=1, fontsize='x-small')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust the rect parameter to make space for the legend\n",
    "    plt.show()\n",
    "\n",
    "with plt.rc_context({\"figure.figsize\": (12, 12), \"figure.dpi\": (300)}):\n",
    "    plot_single_umap_colored(adata, \"Metadata_cmpdName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "def make_jointplot_seaborn_density_anndata(adata, colouring, dmso_name, cmpd, save_path = None, overlay=False, overlay_df=None):\n",
    "    \n",
    "    umap_data = pd.DataFrame(adata.obsm['X_umap'], columns=['UMAP1', 'UMAP2']).reset_index()\n",
    "    embedding = pd.concat([umap_data,pd.DataFrame(adata.obs).reset_index()], axis = 1)\n",
    "    embedding = embedding.reset_index()\n",
    "    embedding[\"Metadata_cmpdNameConc2\"] = embedding[\"Metadata_cmpdName\"].astype(str) + \"_\" + embedding[\"Metadata_cmpdConc\"].astype(str)\n",
    "\n",
    "\n",
    "    def get_color(val):\n",
    "        if dmso_name in val:\n",
    "            return \"lightgrey\"\n",
    "        else:\n",
    "            return \"#e96565\"  # This color will be overridden for non-[DMSO] treatments\n",
    "    \n",
    "    def get_size(val):\n",
    "        return 10 if val != dmso_name else 3\n",
    "    \n",
    "    embedding['color'] = embedding[colouring].apply(get_color)\n",
    "    embedding['size'] = embedding[colouring].apply(get_size)\n",
    "\n",
    "    all_treatments = list(embedding[colouring].unique())\n",
    "    sorted_treatments = all_treatments.copy()\n",
    "    specific_value = dmso_name\n",
    "    if specific_value in sorted_treatments:\n",
    "        sorted_treatments.remove(specific_value)\n",
    "    sorted_treatments.insert(0, specific_value)\n",
    "\n",
    "    g = sns.JointGrid(x='UMAP1', y='UMAP2', data=embedding, height=10)\n",
    "\n",
    "    #cmap = plt.cm.viridis\n",
    "    cmap = plt.cm.jet\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    is_dmso_only = len(all_treatments) == 1 and all_treatments[0] == dmso_name\n",
    "\n",
    "    for treatment in sorted_treatments:\n",
    "        subset = embedding[embedding[colouring] == treatment]\n",
    "        \n",
    "        if is_dmso_only:\n",
    "            values = np.vstack([subset[\"UMAP1\"], subset[\"UMAP2\"]])\n",
    "            kernel = stats.gaussian_kde(values)(values)\n",
    "            colors = cmap(kernel)\n",
    "\n",
    "            # Plot KDE for x and y axes\n",
    "            sns.kdeplot(x=subset[\"UMAP1\"], ax=g.ax_marg_x, fill=True, color=colors.mean(axis=0), legend=False)\n",
    "            sns.kdeplot(y=subset[\"UMAP2\"], ax=g.ax_marg_y, fill=True, color=colors.mean(axis=0), legend=False)\n",
    "\n",
    "            # Scatter plot with density color\n",
    "            g.ax_joint.scatter(subset[\"UMAP1\"], subset[\"UMAP2\"], c=kernel, s=subset['size'], cmap=cmap, label=f\"{treatment} - {len(subset)} cells\", alpha=0.7, edgecolor='white', linewidth=0.5)\n",
    "        \n",
    "        else:\n",
    "            if treatment != dmso_name:\n",
    "                # Calculate density for non-[DMSO] treatments\n",
    "                values = np.vstack([subset[\"UMAP1\"], subset[\"UMAP2\"]])\n",
    "                kernel = stats.gaussian_kde(values)(values)\n",
    "                colors = cmap(kernel)\n",
    "\n",
    "                # Plot KDE for x and y axes\n",
    "                sns.kdeplot(x=subset[\"UMAP1\"], ax=g.ax_marg_x, fill=True, color=colors.mean(axis=0), legend=False)\n",
    "                sns.kdeplot(y=subset[\"UMAP2\"], ax=g.ax_marg_y, fill=True, color=colors.mean(axis=0), legend=False)\n",
    "\n",
    "                # Scatter plot with density color\n",
    "                g.ax_joint.scatter(subset[\"UMAP1\"], subset[\"UMAP2\"], c=kernel, s=subset['size'], cmap=cmap, label=f\"{treatment} - {len(subset)} cells\", alpha=0.7, edgecolor='white', linewidth=0.5)\n",
    "            else:\n",
    "                # Plot for [DMSO] treatment\n",
    "                sns.kdeplot(x=subset[\"UMAP1\"], ax=g.ax_marg_x, fill=True, color='lightgrey', legend=False)\n",
    "                sns.kdeplot(y=subset[\"UMAP2\"], ax=g.ax_marg_y, fill=True, color='lightgrey', legend=False)\n",
    "                g.ax_joint.scatter(subset[\"UMAP1\"], subset[\"UMAP2\"], c='lightgrey', s=subset['size'], label=f\"{treatment} - {len(subset)} cells\", alpha=0.7, edgecolor='white', linewidth=0.5)\n",
    "        # Overlay additional points if the option is active\n",
    "    \n",
    "    if overlay and overlay_df is not None:\n",
    "        overlay_df['color'] = overlay_df[colouring].apply(get_color)\n",
    "        overlay_df['size'] = overlay_df[colouring].apply(lambda val: get_size(val) * 2)  \n",
    "        \n",
    "        for treatment in sorted_treatments:\n",
    "            subset = overlay_df[overlay_df[colouring] == treatment]\n",
    "            g.ax_joint.scatter(subset[\"UMAP1\"], subset[\"UMAP2\"], c=subset['color'], s=subset['size'], alpha=0.9, edgecolor='grey', linewidth=0.5)\n",
    "\n",
    "\n",
    "    fig = g.fig  # Get the figure of the JointGrid\n",
    "    cbar_ax = fig.add_axes([0.93, 0.1, 0.02, 0.7])  # Add axes for the colorbar\n",
    "\n",
    "    # Add colorbar to the figure, not the joint plot axes\n",
    "    cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "    cbar.set_label('Relative density', rotation=270, labelpad=15) \n",
    "\n",
    "    # Adjust the figure to make space for the colorbar\n",
    "    fig.subplots_adjust(right=0.9)\n",
    "\n",
    "    g.ax_joint.set_title(cmpd)\n",
    "    g.ax_joint.legend()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_jointplot_seaborn_density_anndata(emb_dict[\"dmso_only\"], \"Metadata_cmpdName\", \"[DMSO]\", \"\", save_path= \"/home/jovyan/share/data/analyses/benjamin/cellxgene/deepprofiler/SPECS3k/figures/dmso_density_umap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scanpy density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.embedding_density(emb_dict[\"all\"], basis='umap', groupby = \"Metadata_cmpdName\")\n",
    "sc.pl.embedding_density(adata, basis='umap', key='umap_density_Metadata_cmpdName', save = f\"figures/Metadata_cmpdName_density_umap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding_density(emb_dict[\"all\"], bg_dotsize= 30, fg_dotsize= 40, basis = \"umap\",key='umap_density_Metadata_cmpdName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary stats and heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_features = grit_filter_df_sampled_pd[features_fixed].describe(percentiles= [0.05, 0.95, 0.5])\n",
    "min_of_min = summary_features.loc['min'].min()  # Minimum of the 'min' values\n",
    "max_of_max = summary_features.loc['max'].max()  # Maximum of the 'max' values\n",
    "max_of_95th = summary_features.loc['95%'].max()  # Maximum of the '95th percentile' values\n",
    "min_of_5th = summary_features.loc['5%'].min()  \n",
    "print(\"Minimum of 'min' values:\", min_of_min)\n",
    "print(\"Maximum of 'max' values:\", max_of_max)\n",
    "print(\"Maximum of '95th percentile' values:\", max_of_95th)\n",
    "print(\"Minimum of '5th percentile' values:\", min_of_5th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary_stats(df):\n",
    "    features = df.columns\n",
    "\n",
    "# Plotting\n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    # Mean line\n",
    "    plt.plot(features, df.loc['mean'], label='Mean', color='blue')\n",
    "\n",
    "    # 5th percentile line\n",
    "    plt.plot(features, df.loc['5%'], label='5th Percentile', color='green')\n",
    "\n",
    "    # 95th percentile line\n",
    "    plt.plot(features, df.loc['95%'], label='95th Percentile', color='red')\n",
    "\n",
    "    # Max values as dots\n",
    "    plt.scatter(features, df.loc['max'], color='black', label='Max', s=5)  # s is the size of points\n",
    "    plt.scatter(features, df.loc['min'], color='grey', label='Min', s=5)\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Feature distributions')\n",
    "    plt.xticks([])  # Rotate feature names for readability\n",
    "\n",
    "    # Legend\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_summary_stats(summary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_feature_statistics(df, group_column, feature_columns):\n",
    "    \"\"\"\n",
    "    Plot statistical summaries (mean, 5th, 95th percentiles, and max) of features for each group in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The original pandas DataFrame with data.\n",
    "    group_column (str): The name of the column to group by.\n",
    "    feature_columns (list): List of columns to calculate statistics on.\n",
    "    \"\"\"\n",
    "    # Grouping the DataFrame by the specified column\n",
    "    grouped = df.groupby(group_column)\n",
    "\n",
    "    # Determine the number of subplots needed\n",
    "    n_groups = len(grouped)\n",
    "    n_cols = 1  # You can adjust the number of columns per row\n",
    "    n_rows = int(np.ceil(n_groups / n_cols))\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15 * n_cols, 10 * n_rows), squeeze=False)\n",
    "    axes = axes.flatten()  # Flatten to 1D array for easy iteration\n",
    "\n",
    "    for i, (group_name, group_data) in enumerate(grouped):\n",
    "        # Calculating statistics for the group\n",
    "        mean = group_data[feature_columns].mean()\n",
    "        std = group_data[feature_columns].std()\n",
    "        min_val = group_data[feature_columns].min()\n",
    "        max_val = group_data[feature_columns].max()\n",
    "        percentile_5 = group_data[feature_columns].quantile(0.05)\n",
    "        percentile_95 = group_data[feature_columns].quantile(0.95)\n",
    "\n",
    "        # Plotting on the ith subplot\n",
    "        ax = axes[i]\n",
    "        ax.plot(feature_columns, mean, label='Mean', color='blue')\n",
    "        ax.plot(feature_columns, percentile_5, label='5th Percentile', color='green')\n",
    "        ax.plot(feature_columns, percentile_95, label='95th Percentile', color='red')\n",
    "\n",
    "\n",
    "        ax.set_title(f'Group: {group_name}')\n",
    "        ax.set_xticks([])  # Remove x-axis labels\n",
    "\n",
    "        if i == 0:  # Add legend to the first subplot as an example\n",
    "            ax.legend()\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_grouped_feature_statistics(grit_filter_df_sampled_pd, \"Metadata_cmpdName\", features_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sorted indices\n",
    "sorted_indices = emb_dict[\"all\"].obs[\"subpopulations\"].sort_values().index\n",
    "\n",
    "# Reorder .X and .obs\n",
    "emb_dict[\"all\"] = emb_dict[\"all\"][sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "# Inital setting for plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "\n",
    "def plot_clipped_heatmap(adata, max_val=10, min_val=-10, genes=None, groupby=None):\n",
    "    \"\"\"\n",
    "    Plot a heatmap from clipped data of an AnnData object.\n",
    "\n",
    "    Parameters:\n",
    "    adata (AnnData): The original AnnData object.\n",
    "    max_val (float): Maximum value to clip data to.\n",
    "    min_val (float): Minimum value to clip data to.\n",
    "    genes (list): List of gene names to be plotted. They should match the var_names in adata.\n",
    "    groupby (str): Name of the observation annotation to group by (usually categorical).\n",
    "\n",
    "    Returns:\n",
    "    None: Displays a heatmap.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Make a copy of the AnnData object to avoid overwriting original data\n",
    "    adata_copy = adata.copy()\n",
    "\n",
    "    # Step 2: Clip the data in the X matrix of the copied AnnData object\n",
    "    # Check if 'X' is dense or sparse and clip accordingly\n",
    "    if isinstance(adata_copy.X, np.ndarray):\n",
    "        adata_copy.X = np.clip(adata_copy.X, a_min=min_val, a_max=max_val)\n",
    "    elif isinstance(adata_copy.X, (scipy.sparse.csr_matrix, scipy.sparse.csc_matrix)):\n",
    "        adata_copy.X.data = np.clip(adata_copy.X.data, a_min=min_val, a_max=max_val)\n",
    "    else:\n",
    "        raise TypeError(\"adata.X must be a numpy array or a scipy sparse matrix.\")\n",
    "\n",
    "    rcParams[\"figure.figsize\"]  =(10,10)\n",
    "    # Step 3: Use scanpy's pl.heatmap function to visualize the clipped data\n",
    "    sc.pl.heatmap(adata_copy, var_names=genes, groupby=groupby, swap_axes= True, standard_scale = \"obs\")\n",
    "\n",
    "# Example usage\n",
    "# plot_clipped_heatmap(your_adata_object, max_val=10, min_val=-10, genes=your_genes_list, groupby='your_groupby_column')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"figure.figsize\": (8, 8), \"figure.dpi\": (300)}):\n",
    "    sc.pl.heatmap(emb_dict[\"all\"], var_names=features_fixed, groupby=\"subpopulations\", dendrogram= False, swap_axes= False, vmin = -3, vmax = 3, cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def aggregate_by_group(adata, group_by):\n",
    "    \"\"\"\n",
    "    Aggregate the expression data in an AnnData object by a specified group.\n",
    "    \n",
    "    Parameters:\n",
    "    adata (AnnData): The original AnnData object.\n",
    "    group_by (str): The column in adata.obs to group by.\n",
    "    \n",
    "    Returns:\n",
    "    AnnData: A new AnnData object with aggregated data.\n",
    "    \"\"\"\n",
    "    # Ensure the group_by column is categorical for efficiency\n",
    "    adata.obs[group_by] = adata.obs[group_by].astype('category')\n",
    "    if isinstance(adata.X, (np.ndarray, np.generic)):  # If .X is already a dense matrix\n",
    "         adata_df = pd.DataFrame(adata.X, columns=adata.var_names)\n",
    "    else:  # If .X is a sparse matrix\n",
    "        adata_df  = pd.DataFrame(adata.X.toarray(), columns=adata.var_names)\n",
    "\n",
    "    # Group and aggregate data\n",
    "\n",
    "    adata_df[group_by] = adata.obs[group_by].values\n",
    "    \n",
    "    # Aggregate data by taking the mean for each group\n",
    "    aggregated_data = adata_df.groupby(group_by).median()\n",
    "    # Create a new AnnData object with the aggregated data\n",
    "    # Note: Here we're assuming that the .var information remains the same\n",
    "    # If there are .obs specific fields you'd like to retain or calculate, adjust as needed\n",
    "    aggregated_adata = anndata.AnnData(X=aggregated_data.values, var=adata.var.copy())\n",
    "    aggregated_adata.obs[group_by] = aggregated_data.index.values\n",
    "    \n",
    "    return aggregated_adata\n",
    "\n",
    "# Example usage:\n",
    "# aggregated_adata = aggregate_by_group(your_adata, 'cell_type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = aggregate_by_group(emb_dict[\"all\"], \"subpopulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.dendrogram(aggregated, var_names=features_fixed, groupby=\"subpopulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"figure.figsize\": (8, 8), \"figure.dpi\": (300)}):\n",
    "    sc.pl.heatmap(aggregated, dendrogram=True, var_names=features_fixed, groupby=\"subpopulations\", swap_axes=False, vmin=-3, vmax=3, cmap='RdBu_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.dendrogram(emb_dict[\"all\"], var_names=features_fixed, groupby=\"subpopulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.correlation_matrix(emb_dict[\"all\"], 'subpopulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "def create_heatmap_from_aggregated_adata(adata, groupby_column, title=\"\", cmap='viridis', figsize=(10, 8), vmin=None, vmax=None):\n",
    "    \"\"\"\n",
    "    Create a heatmap from an aggregated AnnData object with specified labels on the y-axis.\n",
    "\n",
    "    Parameters:\n",
    "    adata (AnnData): The aggregated AnnData object.\n",
    "    label_column (str): Column in adata.obs to use for y-axis labels.\n",
    "    title (str, optional): Title of the heatmap.\n",
    "    cmap (str, optional): Colormap for the heatmap.\n",
    "    figsize (tuple, optional): Size of the figure.\n",
    "    vmin, vmax (float, optional): Min and max values for colormap scaling.\n",
    "\n",
    "    Returns:\n",
    "    Heatmap plot\n",
    "    \"\"\"\n",
    "    # Ensure the label column is present\n",
    "    if groupby_column not in adata.obs:\n",
    "        raise ValueError(f\"{groupby_column} not found in adata.obs\")\n",
    "\n",
    "    # Extract group labels and assign colors\n",
    "    group_labels = adata.obs[groupby_column].unique()\n",
    "    colors = sns.color_palette('hsv', len(group_labels))\n",
    "\n",
    "    # Create a color dictionary for the groups\n",
    "    color_dict = dict(zip(group_labels, colors))\n",
    "\n",
    "    # Convert the .X matrix to a DataFrame\n",
    "    data_df = pd.DataFrame(adata.X, index=adata.obs_names, columns=adata.var_names)\n",
    "    # Add the group column for color bar creation\n",
    "    data_df[groupby_column] = adata.obs[groupby_column]\n",
    "\n",
    "    # Creating the heatmap\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = sns.heatmap(data_df.drop(columns=[groupby_column]), cmap=cmap, annot=False, vmin=vmin, vmax=vmax)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('')\n",
    "    plt.xlabel('')\n",
    "    plt.xticks([])  # Remove x-axis tick labels\n",
    "    ax.set_yticklabels(data_df[groupby_column].unique(), rotation=0)\n",
    "\n",
    "    for i in range(data_df.shape[0] - 1):\n",
    "        ax.axhline(i + 1, color='black', lw=1)\n",
    "\n",
    "    # Add lines around the plot\n",
    "    ax.axhline(0, color='black', lw=2)  # Top horizontal line\n",
    "    ax.axhline(data_df.shape[0], color='black', lw=2)  # Bottom horizontal line\n",
    "    #ax.axvline(0, color='black', lw=2)  # Left vertical line\n",
    "    ax.axvline(data_df.shape[1], color='black', lw=2) \n",
    "    xlim = ax.get_xlim()  # Get the current x-axis limits\n",
    "    ax.axvline(x=xlim[1], color='black', lw=2) \n",
    "    # Add color bars\n",
    "    for i, group in enumerate(data_df[groupby_column].unique()):\n",
    "        ax.add_patch(mpatches.Rectangle((0, i), 5, 1, color=color_dict[group]))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap_from_aggregated_adata(aggregated, groupby_column= \"subpopulations\", vmin = -3, vmax = 3, cmap= \"RdBu_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "def create_heatmap_with_dendrogram(adata, groupby_column, title=\"\", cmap='viridis', figsize=(12, 10), vmin=None, vmax=None):\n",
    "    \"\"\"\n",
    "    Create a heatmap from an aggregated AnnData object with a dendrogram based on groupings.\n",
    "\n",
    "    Parameters:\n",
    "    adata (AnnData): The aggregated AnnData object.\n",
    "    groupby_column (str): Column in adata.obs to use for groupings.\n",
    "    title (str, optional): Title of the heatmap.\n",
    "    cmap (str, optional): Colormap for the heatmap.\n",
    "    figsize (tuple, optional): Size of the figure.\n",
    "    vmin, vmax (float, optional): Min and max values for colormap scaling.\n",
    "\n",
    "    Returns:\n",
    "    Heatmap plot with a dendrogram\n",
    "    \"\"\"\n",
    "    if groupby_column not in adata.obs:\n",
    "        raise ValueError(f\"{groupby_column} not found in adata.obs\")\n",
    "\n",
    "    # Convert the .X matrix to a DataFrame and add group labels\n",
    "    data_df = pd.DataFrame(adata.X, index=adata.obs_names, columns=adata.var_names)\n",
    "    data_df[groupby_column] = adata.obs[groupby_column]\n",
    "\n",
    "    # Perform hierarchical clustering\n",
    "    grouped = data_df.groupby(groupby_column).mean()\n",
    "    Z = sch.linkage(grouped, method='average')\n",
    "\n",
    "    # Create a dendrogram\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    dendro = sch.dendrogram(Z, labels=grouped.index, ax=ax, above_threshold_color='black')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Create the heatmap\n",
    "    ax_heatmap = fig.add_axes([0.3, 0.1, 0.6, 0.6])  # Adjust these values as needed for layout\n",
    "    sns.heatmap(grouped.reindex(dendro['ivl']), cmap=cmap, ax=ax_heatmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap_with_dendrogram(aggregated, groupby_column= \"subpopulations\", vmin = -3, vmax = 3, cmap= \"RdBu_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
