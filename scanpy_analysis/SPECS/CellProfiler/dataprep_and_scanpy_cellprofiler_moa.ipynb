{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc \n",
    "import anndata as ad\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def is_meta_column(c):\n",
    "    for ex in '''\n",
    "        Metadata\n",
    "        ^Count\n",
    "        ImageNumber\n",
    "        Object\n",
    "        Parent\n",
    "        Children\n",
    "        Plate\n",
    "        Well\n",
    "        Location\n",
    "        _[XYZ]_\n",
    "        _[XYZ]$\n",
    "        Phase\n",
    "        Scale\n",
    "        Scaling\n",
    "        BoundingBox\n",
    "        Width\n",
    "        Height\n",
    "        Group\n",
    "        FileName\n",
    "        PathName\n",
    "        URL\n",
    "        Execution\n",
    "        ModuleError\n",
    "        LargeBrightArtefact\n",
    "        label\n",
    "    '''.split():\n",
    "        if re.search(ex, c):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols_specs_moa = [\n",
    "            'Metadata_Plate',\n",
    "            'Metadata_Well',\n",
    "            'Metadata_Site',\n",
    "            'Metadata_cmpdName',\n",
    "            'compound_name',\n",
    "            'Compound',\n",
    "            'moa_broad',\n",
    "            'target',\n",
    "            'moa',\n",
    "            'Synonyms',\n",
    "            'CAS No.',\n",
    "            'M.Wt',\n",
    "            'Information',\n",
    "            'Formula',\n",
    "            'Smiles',\n",
    "            'Solubility',\n",
    "            'URL',\n",
    "            'Pathway',\n",
    "            'concentration_uM',\n",
    "            'grit_score',\n",
    "            'flag',\n",
    "            'secondary_target',\n",
    "            'SPECS_name',\n",
    "            'BatchID',\n",
    "            'SPECS_moa',\n",
    "            'SPECS_target',\n",
    "            'SPECS_name2',\n",
    "            'grit',\n",
    "            'count',\n",
    "            'smiles',\n",
    "            'inchi',\n",
    "            'inkey',\n",
    "            'compound_name_right',\n",
    "            'label',\n",
    "            'project']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols_specs_moa_df = ['Metadata_cmpdName',\n",
    " 'moa',\n",
    " 'Metadata_Plate',\n",
    " 'Metadata_Well',\n",
    " 'Metadata_Site',\n",
    " 'compound_name',\n",
    " 'Nuclei_Location_Center_X',\n",
    " 'Nuclei_Location_Center_Y',\n",
    " 'project',\n",
    " \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = \"/home/jovyan/share/data/analyses/benjamin/Single_cell_supervised\"\n",
    "ROOT_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "import pandas as pd\n",
    "sc_profiles = pl.read_parquet(os.path.join(PROJECT_DIR, 'BF_MOA/CellProfiler/datasets/specs5k_undersampled_significant_CP_BF.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_profiles = sc_profiles.drop(\"AreaShape_FormFactor_nuclei\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_fixed = [col for col in sc_profiles.columns if col not in meta_cols_specs_moa_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_counts = []\n",
    "\n",
    "# Iterate through each column, checking if it's numeric and counting NaN values if so\n",
    "for col_name in sc_profiles[features_fixed].columns:\n",
    "    if sc_profiles[features_fixed][col_name].dtype in [pl.Float32, pl.Float64]:\n",
    "        na_count = sc_profiles[features_fixed][col_name].is_nan().sum()\n",
    "        na_counts.append((col_name, na_count))\n",
    "\n",
    "# Convert the list of tuples to a DataFrame\n",
    "na_summary_df = pl.DataFrame(na_counts)\n",
    "na_summary_df = na_summary_df.sort(\"column_1\", descending=True)\n",
    "\n",
    "print(na_summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run scanpy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.AnnData(X = sc_profiles[features_fixed].to_pandas().astype('float32'), obs = sc_profiles[meta_cols_specs_moa_df].to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nan_mask = np.isnan(adata.X)\n",
    "nan_indices = np.where(nan_mask)\n",
    "\n",
    "# Assuming column names are stored in adata.var_names\n",
    "column_names = np.array(adata.var_names)[nan_indices[1]]\n",
    "\n",
    "# Creating a Polars DataFrame\n",
    "df_nans = pl.DataFrame({\n",
    "        \"Row_Index\": nan_indices[0],\n",
    "        \"Column_Index\": nan_indices[1],\n",
    "        \"Column_Name\": column_names\n",
    "    })\n",
    "\n",
    "print(df_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scanpy(adata):\n",
    "    sc.tl.pca(adata, svd_solver='arpack', n_comps= 50)\n",
    "    sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50)\n",
    "    sc.tl.paga(adata, groups = \"Metadata_cmpdName\")\n",
    "    sc.pl.paga(adata, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "    sc.tl.umap(adata, init_pos='random')\n",
    "    #sc.tl.leiden(adata, key_added='clusters', resolution=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_scanpy(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(adata)\n",
    "sc.pl.pca_loadings(adata, components = '1,2,3,4,5')\n",
    "sc.pl.pca(adata, color = \"moa\")\n",
    "sc.pl.umap(adata, color = \"moa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad(\"data/sc_embedding_BF_undersampled_sign_CP.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'adata' is your AnnData object\n",
    "# Extract unique categories excluding 'dmso'\n",
    "categories = adata.obs['moa'].unique().tolist()\n",
    "categories.remove('dmso')  # Remove 'dmso' to handle it separately\n",
    "\n",
    "# Divide categories into two groups (example based on alphabetical order or any other criterion)\n",
    "half = len(categories) // 2\n",
    "group1 = categories[:half]\n",
    "group2 = categories[half:]\n",
    "group1.append('dmso')\n",
    "group2.append('dmso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_density_plots(adata, basis, group_categories, plot_key_prefix):\n",
    "    # Create a temporary column for grouping\n",
    "    temp_group_col = 'temp_group'\n",
    "    adata.obs[temp_group_col] = adata.obs['moa'].apply(lambda x: x if x in group_categories else None)\n",
    "    \n",
    "    # Generate and plot density\n",
    "    sc.tl.embedding_density(adata, basis=basis, groupby=temp_group_col)\n",
    "    sc.pl.embedding_density(adata, basis=basis, key=f'{basis}_density_{temp_group_col}', \n",
    "                            save=f\"moa/sc_BF_sign_{plot_key_prefix}_density_{basis}.png\")\n",
    "    \n",
    "    # Clean up temporary column\n",
    "    del adata.obs[temp_group_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_density_plots(adata, 'umap', group2, 'group2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_per_col = adata_copy.X.mean(axis=0)\n",
    "col_remove = np.where(mean_per_col > 1)[0]\n",
    "new_adata = adata_copy[:, ~adata.var.index.isin(col_remove)]\n",
    "new_adata = new_adata[~new_adata.obs.index.isin(col_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_per_col = adata_copy.X.mean(axis=0)\n",
    "bigger = mean_per_col > 1\n",
    "smaller = mean_per_col < -1\n",
    "col_remove = np.where(bigger|smaller)[0]\n",
    "X = np.delete(adata_copy.X, col_remove, axis = 1)\n",
    "var_names = np.delete(adata_copy.var_names, col_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_scanpy_debug(testing_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(adata)\n",
    "sc.pl.pca_loadings(adata, components = '1,2,3,4,5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca(adata, color = \"moa_broad\")\n",
    "sc.pl.umap(adata, color = \"Metadata_cmpdName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write('grit_reference_locations_cellprofiler_test.h5ad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad(\"data/sc_features_SPECS3k_ref_cellprofiler.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in cellxgene embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CXG_DIR = \"/home/jovyan/share/data/analyses/benjamin/cellxgene/embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_keys(adata):\n",
    "    def find_key_with_substring(obsm, substring):\n",
    "        for key in obsm.keys():\n",
    "            if substring in key:\n",
    "                return key\n",
    "        return None\n",
    "\n",
    "    # Find the keys\n",
    "    pca_key = find_key_with_substring(adata.obsm, 'pca')\n",
    "    umap_key = find_key_with_substring(adata.obsm, 'dmso')\n",
    "    if umap_key == None:\n",
    "        umap_key = find_key_with_substring(adata.obsm, 'emb')\n",
    "\n",
    "    # Rename the keys if they are found\n",
    "    if pca_key:\n",
    "        adata.obsm['X_pca'] = adata.obsm[pca_key]\n",
    "        #del adata.obsm[pca_key]\n",
    "\n",
    "    if umap_key:\n",
    "        adata.obsm['X_umap'] = adata.obsm[umap_key]\n",
    "        #del adata.obsm[umap_key]\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "import anndata as ad\n",
    "emb_dict = {}\n",
    "ref_comp = [\"berb\", \"cao\", \"etop\", \"fenb\", \"flup\", \"tetr\", \"dmso_only\"]\n",
    "h5ad_files = [file for file in os.listdir(CXG_DIR) if file.endswith(\".h5ad\")]\n",
    "\n",
    "for comp in tqdm.tqdm(ref_comp):\n",
    "   for filename in h5ad_files:\n",
    "        # Check if the current string is in the filename\n",
    "        if comp in filename and filename.endswith(\".h5ad\"):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(CXG_DIR, filename)\n",
    "            # Load the .h5ad file\n",
    "            temp = ad.read_h5ad(file_path)\n",
    "            temp_fix = fix_keys(temp)\n",
    "            emb_dict[comp] = temp_fix\n",
    "            # Optional: Print a message\n",
    "            print(f\"Loaded {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ad.read_h5ad(os.path.join(CXG_DIR, \"umap.h5ad\"))\n",
    "temp_fix = fix_keys(temp)\n",
    "emb_dict[\"all\"] = temp_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "# Inital setting for plot\n",
    "from matplotlib import rcParams\n",
    "with plt.rc_context({\"figure.figsize\": (8, 8), \"figure.dpi\": (300)}):\n",
    "    for key, item in emb_dict.items():\n",
    "        print(key)\n",
    "        sc.pl.umap(item, color = \"subpopulations\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_umap_grid_colored(anndata_dict, color_by, n_cols=3):\n",
    "    \"\"\"\n",
    "    Create a grid of UMAP plots from a dictionary of AnnData objects, colored by a specified column.\n",
    "    \n",
    "    Parameters:\n",
    "    anndata_dict (dict): A dictionary of AnnData objects.\n",
    "    color_by (str): Column name to color by.\n",
    "    n_cols (int): Number of columns in the grid.\n",
    "    \"\"\"\n",
    "    # Determine all unique categories across all AnnData objects\n",
    "    anndata_dict = {k: v for k, v in anndata_dict.items() if k != 'all'}\n",
    "    all_categories = set()\n",
    "    for adata in anndata_dict.values():\n",
    "        all_categories.update(adata.obs[color_by].astype(str))\n",
    "\n",
    "    # Sort categories for consistent ordering and create color palette\n",
    "    sorted_categories = sorted(list(all_categories))\n",
    "    color_palette = sc.pl.palettes.default_20 # Use any large enough palette or define your own\n",
    "    color_map = {cat: color_palette[i % len(color_palette)] for i, cat in enumerate(sorted_categories)}\n",
    "    #color_map = {'big_dmso': '#1f77b4', 'small_dmso': '#ff7f0e', 'small_FLUP': '#279e68', 'big_FLUP': '#d62728', 'big_ETOP': '#aa40fc', 'small_ETOP': '#8c564b', 'big_TETR': '#e377c2', 'small_TETR': '#b5bd61', 'small_CA-O': '#17becf', 'big_CA-O': '#aec7e8', 'unassigned': '#ffbb78', 'BERB': '#98df8a', 'FEB': '#ff9896'}\n",
    "    print(color_map)\n",
    "    # Set up the figure for subplots\n",
    "    n_rows = int(np.ceil(len(anndata_dict) / n_cols))\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
    "    axs = axs.flatten()  # Flatten to make indexing axs easier\n",
    "\n",
    "    all_handles = []\n",
    "    all_labels = set()\n",
    "    \n",
    "    # Plot UMAP for each AnnData object\n",
    "    for ax, (key, adata) in zip(axs, anndata_dict.items()):\n",
    "        sc.pl.umap(adata, color=color_by, ax=ax, show=False, \n",
    "                   title=key, frameon=False,\n",
    "                   palette=color_map,\n",
    "                   legend_loc = \"none\")  # Apply the consistent color map\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        all_handles.extend(handles)\n",
    "        all_labels.update(labels)\n",
    "        # Remove axis titles (optional, for cleaner look)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "    # Hide any extra axes\n",
    "    for i in range(len(anndata_dict), len(axs)):\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    # Create an overall title\n",
    "    plt.suptitle('UMAP Grid', fontsize=16)\n",
    "\n",
    "    # Add a single legend outside the plots\n",
    "    # Get handles and labels for legend from the last plot\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=3, bbox_to_anchor=(0.5, 0.01))\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "with plt.rc_context({\"figure.figsize\": (8, 8), \"figure.dpi\": (300)}):\n",
    "    plot_umap_grid_colored(emb_dict, \"subpopulations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def plot_single_umap_colored(adata, color_by):\n",
    "    # Calculate the count of each category in the color_by column\n",
    "    category_counts = adata.obs[color_by].value_counts()\n",
    "\n",
    "    # Create a color palette\n",
    "    #color_map = {'big_dmso': '#1f77b4', 'small_dmso': '#ff7f0e', 'small_FLUP': '#279e68', 'big_FLUP': '#d62728', 'big_ETOP': '#aa40fc', 'small_ETOP': '#8c564b', 'big_TETR': '#e377c2', 'small_TETR': '#b5bd61', 'small_CA-O': '#17becf', 'big_CA-O': '#aec7e8', 'unassigned': '#ffbb78', 'BERB': '#98df8a', 'FEB': '#ff9896'}\n",
    "    color_map = {'berb': '#1f77b4', 'cao': '#ff7f0e', 'dmso_big': '#279e68', 'dmso_small': '#d62728', 'etop_big': '#aa40fc', 'etop_nocluster': '#8c564b', 'etop_small': '#e377c2', 'fenb': '#b5bd61', 'flup': '#17becf', 'tetr_big': '#aec7e8', 'tetr_nocluster': '#ffbb78'}\n",
    "    # Create figure and axis for UMAP plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))  # Adjust figure size as needed\n",
    "\n",
    "    # Create UMAP plot\n",
    "    sc.pl.umap(adata, color=color_by, ax=ax, show=False,\n",
    "               title=f'UMAP colored by {color_by}', \n",
    "               frameon=False, legend_loc='none', \n",
    "               palette=color_map, s = 2)\n",
    "\n",
    "    # Create a custom legend for all categories with counts\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color='w',\n",
    "                              label=f\"{cat} (n={category_counts[cat]})\",\n",
    "                              markerfacecolor=color_map[cat], markersize=10)\n",
    "                       for cat in category_counts.index]\n",
    "\n",
    "    # Place legend outside the plot to the right\n",
    "    ax.legend(handles=legend_elements, title=color_by, loc='center left',\n",
    "              bbox_to_anchor=(1, 0.5), ncol=1, fontsize='x-small')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust the rect parameter to make space for the legend\n",
    "    plt.show()\n",
    "\n",
    "with plt.rc_context({\"figure.figsize\": (12, 12), \"figure.dpi\": (300)}):\n",
    "    plot_single_umap_colored(emb_dict[\"all\"], \"subpopulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_features = grit_filter_df_sampled_pd[features_fixed].describe(percentiles= [0.05, 0.95, 0.5])\n",
    "min_of_min = summary_features.loc['min'].min()  # Minimum of the 'min' values\n",
    "max_of_max = summary_features.loc['max'].max()  # Maximum of the 'max' values\n",
    "max_of_95th = summary_features.loc['95%'].max()  # Maximum of the '95th percentile' values\n",
    "min_of_5th = summary_features.loc['5%'].min()  \n",
    "print(\"Minimum of 'min' values:\", min_of_min)\n",
    "print(\"Maximum of 'max' values:\", max_of_max)\n",
    "print(\"Maximum of '95th percentile' values:\", max_of_95th)\n",
    "print(\"Minimum of '5th percentile' values:\", min_of_5th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary_stats(df):\n",
    "    features = df.columns\n",
    "\n",
    "# Plotting\n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    # Mean line\n",
    "    plt.plot(features, df.loc['mean'], label='Mean', color='blue')\n",
    "\n",
    "    # 5th percentile line\n",
    "    plt.plot(features, df.loc['5%'], label='5th Percentile', color='green')\n",
    "\n",
    "    # 95th percentile line\n",
    "    plt.plot(features, df.loc['95%'], label='95th Percentile', color='red')\n",
    "\n",
    "    # Max values as dots\n",
    "    plt.scatter(features, df.loc['max'], color='black', label='Max', s=5)  # s is the size of points\n",
    "    plt.scatter(features, df.loc['min'], color='grey', label='Min', s=5)\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Feature distributions')\n",
    "    plt.xticks([])  # Rotate feature names for readability\n",
    "\n",
    "    # Legend\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_summary_stats(summary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_feature_statistics(df, group_column, feature_columns):\n",
    "    \"\"\"\n",
    "    Plot statistical summaries (mean, 5th, 95th percentiles, and max) of features for each group in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The original pandas DataFrame with data.\n",
    "    group_column (str): The name of the column to group by.\n",
    "    feature_columns (list): List of columns to calculate statistics on.\n",
    "    \"\"\"\n",
    "    # Grouping the DataFrame by the specified column\n",
    "    grouped = df.groupby(group_column)\n",
    "\n",
    "    # Determine the number of subplots needed\n",
    "    n_groups = len(grouped)\n",
    "    n_cols = 1  # You can adjust the number of columns per row\n",
    "    n_rows = int(np.ceil(n_groups / n_cols))\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15 * n_cols, 10 * n_rows), squeeze=False)\n",
    "    axes = axes.flatten()  # Flatten to 1D array for easy iteration\n",
    "\n",
    "    for i, (group_name, group_data) in enumerate(grouped):\n",
    "        # Calculating statistics for the group\n",
    "        mean = group_data[feature_columns].mean()\n",
    "        std = group_data[feature_columns].std()\n",
    "        min_val = group_data[feature_columns].min()\n",
    "        max_val = group_data[feature_columns].max()\n",
    "        percentile_5 = group_data[feature_columns].quantile(0.05)\n",
    "        percentile_95 = group_data[feature_columns].quantile(0.95)\n",
    "\n",
    "        # Plotting on the ith subplot\n",
    "        ax = axes[i]\n",
    "        ax.plot(feature_columns, mean, label='Mean', color='blue')\n",
    "        ax.plot(feature_columns, percentile_5, label='5th Percentile', color='green')\n",
    "        ax.plot(feature_columns, percentile_95, label='95th Percentile', color='red')\n",
    "\n",
    "\n",
    "        ax.set_title(f'Group: {group_name}')\n",
    "        ax.set_xticks([])  # Remove x-axis labels\n",
    "\n",
    "        if i == 0:  # Add legend to the first subplot as an example\n",
    "            ax.legend()\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_grouped_feature_statistics(grit_filter_df_sampled_pd, \"Metadata_cmpdName\", features_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sorted indices\n",
    "sorted_indices = emb_dict[\"all\"].obs[\"subpopulations\"].sort_values().index\n",
    "\n",
    "# Reorder .X and .obs\n",
    "emb_dict[\"all\"] = emb_dict[\"all\"][sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "# Inital setting for plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "\n",
    "def plot_clipped_heatmap(adata, max_val=10, min_val=-10, genes=None, groupby=None):\n",
    "    \"\"\"\n",
    "    Plot a heatmap from clipped data of an AnnData object.\n",
    "\n",
    "    Parameters:\n",
    "    adata (AnnData): The original AnnData object.\n",
    "    max_val (float): Maximum value to clip data to.\n",
    "    min_val (float): Minimum value to clip data to.\n",
    "    genes (list): List of gene names to be plotted. They should match the var_names in adata.\n",
    "    groupby (str): Name of the observation annotation to group by (usually categorical).\n",
    "\n",
    "    Returns:\n",
    "    None: Displays a heatmap.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Make a copy of the AnnData object to avoid overwriting original data\n",
    "    adata_copy = adata.copy()\n",
    "\n",
    "    # Step 2: Clip the data in the X matrix of the copied AnnData object\n",
    "    # Check if 'X' is dense or sparse and clip accordingly\n",
    "    if isinstance(adata_copy.X, np.ndarray):\n",
    "        adata_copy.X = np.clip(adata_copy.X, a_min=min_val, a_max=max_val)\n",
    "    elif isinstance(adata_copy.X, (scipy.sparse.csr_matrix, scipy.sparse.csc_matrix)):\n",
    "        adata_copy.X.data = np.clip(adata_copy.X.data, a_min=min_val, a_max=max_val)\n",
    "    else:\n",
    "        raise TypeError(\"adata.X must be a numpy array or a scipy sparse matrix.\")\n",
    "\n",
    "    rcParams[\"figure.figsize\"]  =(10,10)\n",
    "    # Step 3: Use scanpy's pl.heatmap function to visualize the clipped data\n",
    "    sc.pl.heatmap(adata_copy, var_names=genes, groupby=groupby, swap_axes= True, standard_scale = \"obs\")\n",
    "\n",
    "# Example usage\n",
    "# plot_clipped_heatmap(your_adata_object, max_val=10, min_val=-10, genes=your_genes_list, groupby='your_groupby_column')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"figure.figsize\": (8, 8), \"figure.dpi\": (300)}):\n",
    "    sc.pl.heatmap(emb_dict[\"all\"], var_names=features_fixed, groupby=\"subpopulations\", dendrogram= False, swap_axes= False, vmin = -3, vmax = 3, cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def aggregate_by_group(adata, group_by):\n",
    "    \"\"\"\n",
    "    Aggregate the expression data in an AnnData object by a specified group.\n",
    "    \n",
    "    Parameters:\n",
    "    adata (AnnData): The original AnnData object.\n",
    "    group_by (str): The column in adata.obs to group by.\n",
    "    \n",
    "    Returns:\n",
    "    AnnData: A new AnnData object with aggregated data.\n",
    "    \"\"\"\n",
    "    # Ensure the group_by column is categorical for efficiency\n",
    "    adata.obs[group_by] = adata.obs[group_by].astype('category')\n",
    "    if isinstance(adata.X, (np.ndarray, np.generic)):  # If .X is already a dense matrix\n",
    "         adata_df = pd.DataFrame(adata.X, columns=adata.var_names)\n",
    "    else:  # If .X is a sparse matrix\n",
    "        adata_df  = pd.DataFrame(adata.X.toarray(), columns=adata.var_names)\n",
    "\n",
    "    # Group and aggregate data\n",
    "\n",
    "    adata_df[group_by] = adata.obs[group_by].values\n",
    "    \n",
    "    # Aggregate data by taking the mean for each group\n",
    "    aggregated_data = adata_df.groupby(group_by).median()\n",
    "    # Create a new AnnData object with the aggregated data\n",
    "    # Note: Here we're assuming that the .var information remains the same\n",
    "    # If there are .obs specific fields you'd like to retain or calculate, adjust as needed\n",
    "    aggregated_adata = anndata.AnnData(X=aggregated_data.values, var=adata.var.copy())\n",
    "    aggregated_adata.obs[group_by] = aggregated_data.index.values\n",
    "    \n",
    "    return aggregated_adata\n",
    "\n",
    "# Example usage:\n",
    "# aggregated_adata = aggregate_by_group(your_adata, 'cell_type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = aggregate_by_group(emb_dict[\"all\"], \"subpopulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.dendrogram(aggregated, var_names=features_fixed, groupby=\"subpopulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"figure.figsize\": (8, 8), \"figure.dpi\": (300)}):\n",
    "    sc.pl.heatmap(aggregated, dendrogram=True, var_names=features_fixed, groupby=\"subpopulations\", swap_axes=False, vmin=-3, vmax=3, cmap='RdBu_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.dendrogram(emb_dict[\"all\"], var_names=features_fixed, groupby=\"subpopulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.correlation_matrix(emb_dict[\"all\"], 'subpopulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "def create_heatmap_from_aggregated_adata(adata, groupby_column, title=\"\", cmap='viridis', figsize=(10, 8), vmin=None, vmax=None):\n",
    "    \"\"\"\n",
    "    Create a heatmap from an aggregated AnnData object with specified labels on the y-axis.\n",
    "\n",
    "    Parameters:\n",
    "    adata (AnnData): The aggregated AnnData object.\n",
    "    label_column (str): Column in adata.obs to use for y-axis labels.\n",
    "    title (str, optional): Title of the heatmap.\n",
    "    cmap (str, optional): Colormap for the heatmap.\n",
    "    figsize (tuple, optional): Size of the figure.\n",
    "    vmin, vmax (float, optional): Min and max values for colormap scaling.\n",
    "\n",
    "    Returns:\n",
    "    Heatmap plot\n",
    "    \"\"\"\n",
    "    # Ensure the label column is present\n",
    "    if groupby_column not in adata.obs:\n",
    "        raise ValueError(f\"{groupby_column} not found in adata.obs\")\n",
    "\n",
    "    # Extract group labels and assign colors\n",
    "    group_labels = adata.obs[groupby_column].unique()\n",
    "    colors = sns.color_palette('hsv', len(group_labels))\n",
    "\n",
    "    # Create a color dictionary for the groups\n",
    "    color_dict = dict(zip(group_labels, colors))\n",
    "\n",
    "    # Convert the .X matrix to a DataFrame\n",
    "    data_df = pd.DataFrame(adata.X, index=adata.obs_names, columns=adata.var_names)\n",
    "    # Add the group column for color bar creation\n",
    "    data_df[groupby_column] = adata.obs[groupby_column]\n",
    "\n",
    "    # Creating the heatmap\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = sns.heatmap(data_df.drop(columns=[groupby_column]), cmap=cmap, annot=False, vmin=vmin, vmax=vmax)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('')\n",
    "    plt.xlabel('')\n",
    "    plt.xticks([])  # Remove x-axis tick labels\n",
    "    ax.set_yticklabels(data_df[groupby_column].unique(), rotation=0)\n",
    "\n",
    "    for i in range(data_df.shape[0] - 1):\n",
    "        ax.axhline(i + 1, color='black', lw=1)\n",
    "\n",
    "    # Add lines around the plot\n",
    "    ax.axhline(0, color='black', lw=2)  # Top horizontal line\n",
    "    ax.axhline(data_df.shape[0], color='black', lw=2)  # Bottom horizontal line\n",
    "    #ax.axvline(0, color='black', lw=2)  # Left vertical line\n",
    "    ax.axvline(data_df.shape[1], color='black', lw=2) \n",
    "    xlim = ax.get_xlim()  # Get the current x-axis limits\n",
    "    ax.axvline(x=xlim[1], color='black', lw=2) \n",
    "    # Add color bars\n",
    "    for i, group in enumerate(data_df[groupby_column].unique()):\n",
    "        ax.add_patch(mpatches.Rectangle((0, i), 5, 1, color=color_dict[group]))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap_from_aggregated_adata(aggregated, groupby_column= \"subpopulations\", vmin = -3, vmax = 3, cmap= \"RdBu_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "def create_heatmap_with_dendrogram(adata, groupby_column, title=\"\", cmap='viridis', figsize=(12, 10), vmin=None, vmax=None):\n",
    "    \"\"\"\n",
    "    Create a heatmap from an aggregated AnnData object with a dendrogram based on groupings.\n",
    "\n",
    "    Parameters:\n",
    "    adata (AnnData): The aggregated AnnData object.\n",
    "    groupby_column (str): Column in adata.obs to use for groupings.\n",
    "    title (str, optional): Title of the heatmap.\n",
    "    cmap (str, optional): Colormap for the heatmap.\n",
    "    figsize (tuple, optional): Size of the figure.\n",
    "    vmin, vmax (float, optional): Min and max values for colormap scaling.\n",
    "\n",
    "    Returns:\n",
    "    Heatmap plot with a dendrogram\n",
    "    \"\"\"\n",
    "    if groupby_column not in adata.obs:\n",
    "        raise ValueError(f\"{groupby_column} not found in adata.obs\")\n",
    "\n",
    "    # Convert the .X matrix to a DataFrame and add group labels\n",
    "    data_df = pd.DataFrame(adata.X, index=adata.obs_names, columns=adata.var_names)\n",
    "    data_df[groupby_column] = adata.obs[groupby_column]\n",
    "\n",
    "    # Perform hierarchical clustering\n",
    "    grouped = data_df.groupby(groupby_column).mean()\n",
    "    Z = sch.linkage(grouped, method='average')\n",
    "\n",
    "    # Create a dendrogram\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    dendro = sch.dendrogram(Z, labels=grouped.index, ax=ax, above_threshold_color='black')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Create the heatmap\n",
    "    ax_heatmap = fig.add_axes([0.3, 0.1, 0.6, 0.6])  # Adjust these values as needed for layout\n",
    "    sns.heatmap(grouped.reindex(dendro['ivl']), cmap=cmap, ax=ax_heatmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap_with_dendrogram(aggregated, groupby_column= \"subpopulations\", vmin = -3, vmax = 3, cmap= \"RdBu_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
